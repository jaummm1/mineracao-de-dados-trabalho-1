{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e64ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Importação das bibliotecas ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226f378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleção de Atributos para Modelo de Classificação\n",
    "\n",
    "## Introdução\n",
    "Este trabalho tem como objetivo a utilização de algoritmos de seleção de atributos como parte de um processo de Mineração de Dados para tarefas de classificação. O dataset Airline Passenger Satisfaction contém informações sobre passageiros e queremos prever a satisfação dos clientes (satisfied ou neutral/dissatisfied).\n",
    "\n",
    "### Base de dados\n",
    "O conjunto de dados Airline Passenger Satisfaction contém avaliações de diferentes aspectos da experiência de voo por passageiros. Os atributos incluem:\n",
    "- Informações demográficas: Gênero, idade, tipo de cliente\n",
    "- Detalhes do voo: Classe, tipo de viagem\n",
    "- Avaliações de serviço: Limpeza, conforto do assento, serviço de bordo, etc.\n",
    "- Atrasos em chegadas e partidas\n",
    "\n",
    "### Objetivo\n",
    "Desenvolver um modelo de classificação preciso e interpretável para prever a satisfação dos passageiros, utilizando técnicas de seleção de atributos para melhorar a performance e identificar os fatores mais importantes que influenciam a satisfação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abd2124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Carregamento dos dados ---\n",
    "dados = pd.read_csv('/content/drive/MyDrive/airline_Passenger_Satisfaction.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Exclusão dos atributos irrelevantes\n",
    "dados.drop(columns=['Unnamed: 0', 'id'], axis=1, inplace=True)\n",
    "\n",
    "# Exibir as primeiras linhas do dataset\n",
    "print(\"Primeiras 5 linhas do dataset:\")\n",
    "print(dados.head())\n",
    "\n",
    "# Informações sobre o dataset\n",
    "print(\"\\nInformações do dataset:\")\n",
    "print(dados.info())\n",
    "\n",
    "# Estatísticas descritivas\n",
    "print(\"\\nEstatísticas descritivas:\")\n",
    "print(dados.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ea5ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pré-processamento e exploração dos dados\n",
    "Nesta seção, vamos explorar os dados para entender melhor suas características e relações, além de fazer o tratamento necessário para prepará-los para a modelagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798bae16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Análise exploratória ---\n",
    "\n",
    "# Verificar valores ausentes\n",
    "ausentes = pd.DataFrame({\n",
    "    'Quantidade': dados.isnull().sum(),\n",
    "    'Freq. Relativa': dados.isnull().sum() / len(dados) * 100\n",
    "})\n",
    "print(\"Valores ausentes:\")\n",
    "print(ausentes[ausentes['Quantidade'] > 0])\n",
    "\n",
    "# Tratamento dos valores ausentes: substituição dos valores nulos no atributo 'Arrival Delay in Minutes' pela média\n",
    "# Atribuição da média por classe\n",
    "media_satisfied = dados.loc[dados['satisfaction'] == 'satisfied', 'Arrival Delay in Minutes'].mean()\n",
    "media_neutral_dissatisfied = dados.loc[dados['satisfaction'] == 'neutral or dissatisfied', 'Arrival Delay in Minutes'].mean()\n",
    "\n",
    "# Substituição dos valores nulos pela média de acordo com a classe\n",
    "dados.loc[(dados['satisfaction'] == 'satisfied') & (dados['Arrival Delay in Minutes'].isnull()), 'Arrival Delay in Minutes'] = media_satisfied\n",
    "dados.loc[(dados['satisfaction'] == 'neutral or dissatisfied') & (dados['Arrival Delay in Minutes'].isnull()), 'Arrival Delay in Minutes'] = media_neutral_dissatisfied\n",
    "\n",
    "# Verificar distribuição da variável alvo\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='satisfaction', data=dados)\n",
    "plt.title('Distribuição da Satisfação dos Passageiros')\n",
    "plt.show()\n",
    "\n",
    "# Transformação das variáveis categóricas\n",
    "lista_categoricas = ['Gender', 'Customer Type', 'Type of Travel', 'Class', 'satisfaction']\n",
    "for coluna in lista_categoricas:\n",
    "    if coluna != 'satisfaction':  # Não codificar a variável alvo ainda\n",
    "        le = LabelEncoder()\n",
    "        dados[coluna] = le.fit_transform(dados[coluna])\n",
    "        print(f\"{coluna} - mapeamento: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n",
    "\n",
    "# Visualizar a matriz de correlação\n",
    "plt.figure(figsize=(14, 12))\n",
    "dados_numericos = dados.drop(columns=['satisfaction'])\n",
    "correlacao = dados_numericos.corr()\n",
    "sns.heatmap(correlacao, annot=True, cmap=\"Blues\", fmt=\".2f\")\n",
    "plt.title('Matriz de Correlação')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Boxplots para visualizar a distribuição dos atributos numéricos por classe\n",
    "atributos_numericos = dados.select_dtypes(include=np.number).columns[:5]  # Primeiros 5 atributos numéricos\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(atributos_numericos):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    sns.boxplot(x='satisfaction', y=feature, data=dados)\n",
    "    plt.title(f'{feature} por Satisfação')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cf949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Análise exploratória ---\n",
    "\n",
    "# Verificar valores ausentes\n",
    "ausentes = pd.DataFrame({\n",
    "    'Quantidade': dados.isnull().sum(),\n",
    "    'Freq. Relativa': dados.isnull().sum() / len(dados) * 100\n",
    "})\n",
    "print(\"Valores ausentes:\")\n",
    "print(ausentes[ausentes['Quantidade'] > 0])\n",
    "\n",
    "# Tratamento dos valores ausentes: substituição dos valores nulos no atributo 'Arrival Delay in Minutes' pela média\n",
    "# Atribuição da média por classe\n",
    "media_satisfied = dados.loc[dados['satisfaction'] == 'satisfied', 'Arrival Delay in Minutes'].mean()\n",
    "media_neutral_dissatisfied = dados.loc[dados['satisfaction'] == 'neutral or dissatisfied', 'Arrival Delay in Minutes'].mean()\n",
    "\n",
    "# Substituição dos valores nulos pela média de acordo com a classe\n",
    "dados.loc[(dados['satisfaction'] == 'satisfied') & (dados['Arrival Delay in Minutes'].isnull()), 'Arrival Delay in Minutes'] = media_satisfied\n",
    "dados.loc[(dados['satisfaction'] == 'neutral or dissatisfied') & (dados['Arrival Delay in Minutes'].isnull()), 'Arrival Delay in Minutes'] = media_neutral_dissatisfied\n",
    "\n",
    "# Verificar distribuição da variável alvo\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='satisfaction', data=dados)\n",
    "plt.title('Distribuição da Satisfação dos Passageiros')\n",
    "plt.show()\n",
    "\n",
    "# Transformação das variáveis categóricas\n",
    "lista_categoricas = ['Gender', 'Customer Type', 'Type of Travel', 'Class', 'satisfaction']\n",
    "for coluna in lista_categoricas:\n",
    "    if coluna != 'satisfaction':  # Não codificar a variável alvo ainda\n",
    "        le = LabelEncoder()\n",
    "        dados[coluna] = le.fit_transform(dados[coluna])\n",
    "        print(f\"{coluna} - mapeamento: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n",
    "\n",
    "# Visualizar a matriz de correlação\n",
    "plt.figure(figsize=(14, 12))\n",
    "dados_numericos = dados.drop(columns=['satisfaction'])\n",
    "correlacao = dados_numericos.corr()\n",
    "sns.heatmap(correlacao, annot=True, cmap=\"Blues\", fmt=\".2f\")\n",
    "plt.title('Matriz de Correlação')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Boxplots para visualizar a distribuição dos atributos numéricos por classe\n",
    "atributos_numericos = dados.select_dtypes(include=np.number).columns[:5]  # Primeiros 5 atributos numéricos\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(atributos_numericos):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    sns.boxplot(x='satisfaction', y=feature, data=dados)\n",
    "    plt.title(f'{feature} por Satisfação')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d657d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Divisão em conjunto de treinamento e teste\n",
    "Dividimos os dados em conjuntos de treinamento (80%) e teste (20%) para avaliar o desempenho do modelo em dados não vistos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadc0cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Divisão dos dados ---\n",
    "# Codificar a variável alvo para o treinamento\n",
    "le_target = LabelEncoder()\n",
    "Y = le_target.fit_transform(dados['satisfaction'])\n",
    "X = dados.drop('satisfaction', axis=1)\n",
    "\n",
    "# Dividir em treino e teste (80% treino, 20% teste)\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(\n",
    "    X, Y, test_size=validation_size, random_state=seed, stratify=Y)\n",
    "\n",
    "print(f\"Tamanho do conjunto de treino: {X_train.shape[0]} amostras\")\n",
    "print(f\"Tamanho do conjunto de teste: {X_validation.shape[0]} amostras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ac5943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Divisão dos dados ---\n",
    "# Codificar a variável alvo para o treinamento\n",
    "le_target = LabelEncoder()\n",
    "Y = le_target.fit_transform(dados['satisfaction'])\n",
    "X = dados.drop('satisfaction', axis=1)\n",
    "\n",
    "# Dividir em treino e teste (80% treino, 20% teste)\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(\n",
    "    X, Y, test_size=validation_size, random_state=seed, stratify=Y)\n",
    "\n",
    "print(f\"Tamanho do conjunto de treino: {X_train.shape[0]} amostras\")\n",
    "print(f\"Tamanho do conjunto de teste: {X_validation.shape[0]} amostras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e68569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Criação e treinamento dos modelos iniciais ---\n",
    "# Definir métricas de avaliação\n",
    "scoring = 'accuracy'\n",
    "\n",
    "# Algoritmos\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr', max_iter=1000)))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', LinearSVC(max_iter=10000)))\n",
    "\n",
    "# Avaliação de cada modelo com validação cruzada\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = '%s: %f (%f)' % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "# Comparação dos Algoritmos\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(results)\n",
    "plt.title('Comparação dos Algoritmos - Modelos Iniciais')\n",
    "plt.xticks(np.arange(1, len(names) + 1), names)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Avaliar os modelos no conjunto de validação\n",
    "modelos_dict = {}\n",
    "resultados_iniciais = pd.DataFrame(columns=['Modelo', 'Acurácia', 'Precisão', 'Recall', 'F1-Score'])\n",
    "\n",
    "for i, (name, model) in enumerate(models):\n",
    "    # Treinar o modelo\n",
    "    model.fit(X_train, Y_train)\n",
    "    modelos_dict[name] = model\n",
    "    \n",
    "    # Fazer previsões\n",
    "    predictions = model.predict(X_validation)\n",
    "    \n",
    "    # Calcular métricas\n",
    "    acc = accuracy_score(Y_validation, predictions)\n",
    "    report = classification_report(Y_validation, predictions, output_dict=True)\n",
    "    \n",
    "    # Adicionar resultados\n",
    "    resultados_iniciais.loc[i] = [name, acc, \n",
    "                                 report['weighted avg']['precision'], \n",
    "                                 report['weighted avg']['recall'], \n",
    "                                 report['weighted avg']['f1-score']]\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Resultados dos modelos iniciais:\")\n",
    "print(resultados_iniciais)\n",
    "\n",
    "# Selecionar o melhor modelo inicial para comparação posterior\n",
    "melhor_modelo_idx = resultados_iniciais['Acurácia'].idxmax()\n",
    "melhor_modelo_inicial = resultados_iniciais.loc[melhor_modelo_idx, 'Modelo']\n",
    "print(f\"Melhor modelo inicial: {melhor_modelo_inicial} com acurácia de {resultados_iniciais.loc[melhor_modelo_idx, 'Acurácia']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4f5ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seleção de Atributos\n",
    "Agora vamos aplicar diferentes técnicas de seleção de atributos para identificar as características mais relevantes para o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2099ab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. SelectKBest (baseado em qui-quadrado) ---\n",
    "k = 10  # número de atributos a serem selecionados\n",
    "selector_kbest = SelectKBest(score_func=chi2, k=k)\n",
    "X_train_kbest = selector_kbest.fit_transform(X_train, Y_train)\n",
    "X_validation_kbest = selector_kbest.transform(X_validation)\n",
    "\n",
    "# Obter os atributos selecionados\n",
    "atributos_kbest = X.columns[selector_kbest.get_support()]\n",
    "print(\"Atributos selecionados pelo SelectKBest:\")\n",
    "print(list(atributos_kbest))\n",
    "\n",
    "# --- 2. Recursive Feature Elimination (RFE) ---\n",
    "estimator = RandomForestClassifier(random_state=seed)\n",
    "selector_rfe = RFE(estimator, n_features_to_select=k)\n",
    "X_train_rfe = selector_rfe.fit_transform(X_train, Y_train)\n",
    "X_validation_rfe = selector_rfe.transform(X_validation)\n",
    "\n",
    "# Obter os atributos selecionados pelo RFE\n",
    "atributos_rfe = X.columns[selector_rfe.get_support()]\n",
    "print(\"\\nAtributos selecionados pelo RFE:\")\n",
    "print(list(atributos_rfe))\n",
    "\n",
    "# --- 3. Importância de atributos via RandomForest ---\n",
    "rf = RandomForestClassifier(random_state=seed)\n",
    "rf.fit(X_train, Y_train)\n",
    "\n",
    "# Obter importâncias\n",
    "importancias = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "atributos_rf = importancias.sort_values(ascending=False)[:k].index.tolist()\n",
    "\n",
    "print(\"\\nAtributos selecionados pelo Random Forest:\")\n",
    "print(atributos_rf)\n",
    "\n",
    "# Extrair subset do conjunto de dados com os atributos selecionados por RF\n",
    "X_train_rf = X_train[atributos_rf]\n",
    "X_validation_rf = X_validation[atributos_rf]\n",
    "\n",
    "# Visualizar importância dos atributos\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.bar(atributos_kbest, selector_kbest.scores_[selector_kbest.get_support()])\n",
    "plt.title('Importância dos Atributos - SelectKBest')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.bar(atributos_rfe, range(len(atributos_rfe)))\n",
    "plt.title('Atributos Selecionados - RFE')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.bar(X.columns, rf.feature_importances_)\n",
    "plt.title('Importância de Atributos - Random Forest')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac206e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Treinamento e avaliação do modelo com seleção de atributos\n",
    "Agora vamos treinar modelos utilizando apenas os atributos selecionados e comparar seu desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3992e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Treinar modelos com atributos selecionados ---\n",
    "resultados_selecao = pd.DataFrame(columns=['Método', 'Modelo', 'Acurácia', 'Precisão', 'Recall', 'F1-Score'])\n",
    "row_idx = 0\n",
    "\n",
    "# Usar o melhor modelo inicial para comparar as técnicas de seleção de atributos\n",
    "melhor_modelo = [model for name, model in models if name == melhor_modelo_inicial][0]\n",
    "\n",
    "# Modelo com SelectKBest\n",
    "modelo_kbest = type(melhor_modelo)()\n",
    "if isinstance(modelo_kbest, LinearSVC):\n",
    "    modelo_kbest = type(melhor_modelo)(max_iter=10000)\n",
    "modelo_kbest.fit(X_train_kbest, Y_train)\n",
    "pred_kbest = modelo_kbest.predict(X_validation_kbest)\n",
    "acc_kbest = accuracy_score(Y_validation, pred_kbest)\n",
    "report_kbest = classification_report(Y_validation, pred_kbest, output_dict=True)\n",
    "resultados_selecao.loc[row_idx] = ['SelectKBest', melhor_modelo_inicial, \n",
    "                                  acc_kbest,\n",
    "                                  report_kbest['weighted avg']['precision'],\n",
    "                                  report_kbest['weighted avg']['recall'],\n",
    "                                  report_kbest['weighted avg']['f1-score']]\n",
    "row_idx += 1\n",
    "\n",
    "# Modelo com RFE\n",
    "modelo_rfe = type(melhor_modelo)()\n",
    "if isinstance(modelo_rfe, LinearSVC):\n",
    "    modelo_rfe = type(melhor_modelo)(max_iter=10000)\n",
    "modelo_rfe.fit(X_train_rfe, Y_train)\n",
    "pred_rfe = modelo_rfe.predict(X_validation_rfe)\n",
    "acc_rfe = accuracy_score(Y_validation, pred_rfe)\n",
    "report_rfe = classification_report(Y_validation, pred_rfe, output_dict=True)\n",
    "resultados_selecao.loc[row_idx] = ['RFE', melhor_modelo_inicial,\n",
    "                                  acc_rfe, \n",
    "                                  report_rfe['weighted avg']['precision'],\n",
    "                                  report_rfe['weighted avg']['recall'],\n",
    "                                  report_rfe['weighted avg']['f1-score']]\n",
    "row_idx += 1\n",
    "\n",
    "# Modelo com Random Forest Importance\n",
    "modelo_rf = type(melhor_modelo)()\n",
    "if isinstance(modelo_rf, LinearSVC):\n",
    "    modelo_rf = type(melhor_modelo)(max_iter=10000)\n",
    "modelo_rf.fit(X_train_rf, Y_train)\n",
    "pred_rf = modelo_rf.predict(X_validation_rf)\n",
    "acc_rf = accuracy_score(Y_validation, pred_rf)\n",
    "report_rf = classification_report(Y_validation, pred_rf, output_dict=True)\n",
    "resultados_selecao.loc[row_idx] = ['RandomForest', melhor_modelo_inicial,\n",
    "                                  acc_rf, \n",
    "                                  report_rf['weighted avg']['precision'],\n",
    "                                  report_rf['weighted avg']['recall'],\n",
    "                                  report_rf['weighted avg']['f1-score']]\n",
    "row_idx += 1\n",
    "\n",
    "# Adicionar resultados do modelo original para comparação\n",
    "original_acc = resultados_iniciais.loc[melhor_modelo_idx, 'Acurácia']\n",
    "original_precision = resultados_iniciais.loc[melhor_modelo_idx, 'Precisão']\n",
    "original_recall = resultados_iniciais.loc[melhor_modelo_idx, 'Recall']\n",
    "original_f1 = resultados_iniciais.loc[melhor_modelo_idx, 'F1-Score']\n",
    "resultados_selecao.loc[row_idx] = ['Original (Todos)', melhor_modelo_inicial,\n",
    "                                  original_acc, original_precision, original_recall, original_f1]\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Resultados com seleção de atributos:\")\n",
    "print(resultados_selecao)\n",
    "\n",
    "# Visualizar comparação dos resultados\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Método', y='Acurácia', data=resultados_selecao)\n",
    "plt.title('Comparação de Acurácia entre Métodos de Seleção de Atributos')\n",
    "plt.ylim(0.8, 1.0)  # Ajustar conforme necessário\n",
    "plt.show()\n",
    "\n",
    "# Encontrar a melhor técnica de seleção\n",
    "melhor_selecao_idx = resultados_selecao['Acurácia'].idxmax()\n",
    "melhor_metodo = resultados_selecao.loc[melhor_selecao_idx, 'Método']\n",
    "melhor_acc = resultados_selecao.loc[melhor_selecao_idx, 'Acurácia']\n",
    "\n",
    "# Obter os atributos da melhor técnica de seleção\n",
    "if melhor_metodo == 'SelectKBest':\n",
    "    atributos_selecionados = atributos_kbest\n",
    "elif melhor_metodo == 'RFE':\n",
    "    atributos_selecionados = atributos_rfe\n",
    "elif melhor_metodo == 'RandomForest':\n",
    "    atributos_selecionados = atributos_rf\n",
    "else:\n",
    "    atributos_selecionados = X.columns.tolist()\n",
    "\n",
    "print(f\"\\nMelhor método de seleção: {melhor_metodo} com acurácia de {melhor_acc:.4f}\")\n",
    "print(f\"Atributos selecionados: {atributos_selecionados}\")\n",
    "\n",
    "# Matriz de confusão para o melhor modelo com seleção de atributos\n",
    "if melhor_metodo == 'SelectKBest':\n",
    "    cm = confusion_matrix(Y_validation, pred_kbest)\n",
    "    pred_final = pred_kbest\n",
    "elif melhor_metodo == 'RFE':\n",
    "    cm = confusion_matrix(Y_validation, pred_rfe)\n",
    "    pred_final = pred_rfe\n",
    "elif melhor_metodo == 'RandomForest':\n",
    "    cm = confusion_matrix(Y_validation, pred_rf)\n",
    "    pred_final = pred_rf\n",
    "else:\n",
    "    best_model = modelos_dict[melhor_modelo_inicial]\n",
    "    pred_final = best_model.predict(X_validation)\n",
    "    cm = confusion_matrix(Y_validation, pred_final)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "           xticklabels=['Insatisfeito', 'Satisfeito'],\n",
    "           yticklabels=['Insatisfeito', 'Satisfeito'])\n",
    "plt.xlabel('Previsto')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusão - Melhor Modelo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f8a269",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Discussão dos resultados\n",
    "Nesta seção, interpretamos os resultados obtidos pelos diferentes modelos e técnicas de seleção de atributos.\n",
    "\n",
    "1. **Comparação de técnicas de seleção de atributos**:\n",
    "   - O SelectKBest utilizou o teste qui-quadrado para selecionar atributos com maior dependência estatística com a variável alvo.\n",
    "   - O RFE eliminou recursivamente atributos, mantendo apenas os mais importantes para a classificação.\n",
    "   - A técnica baseada em Random Forest utilizou a importância dos atributos calculada internamente pelo algoritmo.\n",
    "\n",
    "2. **Impacto na performance dos modelos**:\n",
    "   - A seleção de atributos permitiu identificar as características mais importantes para a satisfação dos passageiros.\n",
    "   - Alguns métodos de seleção conseguiram manter ou até melhorar a performance do modelo com menos atributos.\n",
    "   - A redução de dimensionalidade simplificou os modelos e potencialmente melhorou a generalização.\n",
    "\n",
    "3. **Atributos mais importantes**:\n",
    "   - [Discussão sobre os atributos mais importantes identificados]\n",
    "   - Esses atributos mostram que a satisfação do passageiro está fortemente relacionada a [fatores específicos como conforto, serviço de bordo, etc.].\n",
    "   - Esta informação é valiosa para companhias aéreas que desejam melhorar a experiência do cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c1a648",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conclusão\n",
    "\n",
    "Este trabalho mostrou a aplicação de técnicas de seleção de atributos em um problema de classificação para prever a satisfação de passageiros de companhias aéreas. As principais conclusões são:\n",
    "\n",
    "1. A seleção de atributos é uma etapa importante no processo de mineração de dados que pode:\n",
    "   - Reduzir a dimensionalidade dos dados e tornar os modelos mais eficientes\n",
    "   - Melhorar a interpretabilidade, destacando os fatores mais importantes\n",
    "   - Potencialmente aumentar a acurácia dos modelos ao eliminar ruídos\n",
    "\n",
    "2. Diferentes técnicas de seleção de atributos podem identificar conjuntos distintos de características importantes, com algumas sobreposições significativas.\n",
    "\n",
    "3. O método [melhor método] mostrou-se mais eficaz para este problema, conseguindo [resultado específico].\n",
    "\n",
    "4. Para empresas aéreas, este estudo mostra que os principais fatores que influenciam a satisfação do cliente são [fatores específicos], o que permite direcionar esforços de melhoria nas áreas mais críticas.\n",
    "\n",
    "Trabalhos futuros poderiam explorar outras técnicas de seleção de atributos, algoritmos de classificação mais avançados, e validação cruzada para garantir a robustez dos resultados em diferentes segmentos de passageiros."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
