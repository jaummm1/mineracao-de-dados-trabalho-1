{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10766ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Importação das bibliotecas ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8df58fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleção de Atributos para Modelo de Regressão\n",
    "\n",
    "## Introdução\n",
    "Este trabalho tem como objetivo a utilização de algoritmos de seleção de atributos como parte de um processo de Mineração de Dados para tarefas de regressão. O dataset Boston Housing contém informações sobre casas em Boston e queremos prever o valor médio das casas (MEDV) com base em diferentes características.\n",
    "\n",
    "### Base de dados\n",
    "O conjunto de dados Boston Housing contém informações coletadas pelo Serviço de Recenseamento dos EUA sobre habitações na área de Boston, Massachusetts. Ele inclui características como:\n",
    "- CRIM: taxa de criminalidade per capita\n",
    "- ZN: proporção de terrenos residenciais zoneados para lotes acima de 25.000 sq.ft\n",
    "- INDUS: proporção de acres de negócios não-varejistas por cidade\n",
    "- E outros atributos sobre poluição, número de quartos, idade, etc.\n",
    "\n",
    "### Objetivo\n",
    "Desenvolver um modelo de regressão preciso e interpretável para prever o valor médio das casas, utilizando técnicas de seleção de atributos para melhorar a performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d40eef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Carregamento dos dados ---\n",
    "df = pd.read_csv('/content/drive/MyDrive/boston.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Exibir as primeiras linhas do dataset\n",
    "print(\"Primeiras 5 linhas do dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Informações sobre o dataset\n",
    "print(\"\\nInformações do dataset:\")\n",
    "print(df.info())\n",
    "\n",
    "# Estatísticas descritivas\n",
    "print(\"\\nEstatísticas descritivas:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd89c158",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pré-processamento e exploração dos dados\n",
    "Nesta seção, vamos explorar os dados para entender melhor suas características e relações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bde53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Análise exploratória ---\n",
    "# Verificar correlações com a variável alvo\n",
    "print(\"Correlações com a variável alvo (MEDV):\")\n",
    "correlations = df.corr()['MEDV'].sort_values(ascending=False)\n",
    "print(correlations)\n",
    "\n",
    "# Visualizar a matriz de correlação\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(df.corr(), annot=True, cmap=\"Blues\", fmt=\".2f\")\n",
    "plt.title('Matriz de Correlação')\n",
    "plt.show()\n",
    "\n",
    "# Histogramas para entender a distribuição dos dados\n",
    "plt.figure(figsize=(15, 10))\n",
    "df.hist(figsize=(15, 10), bins=30)\n",
    "plt.suptitle('Histogramas das variáveis')\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "# Scatter plots da variável alvo com os atributos mais correlacionados\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(correlations.index[:5]):\n",
    "    if feature != 'MEDV':\n",
    "        plt.subplot(2, 2, i)\n",
    "        plt.scatter(df[feature], df['MEDV'], alpha=0.5)\n",
    "        plt.title(f'MEDV vs {feature} (corr: {correlations[feature]:.2f})')\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel('MEDV')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea9661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Divisão em conjunto de treinamento e teste\n",
    "Dividimos os dados em conjuntos de treinamento (70%) e teste (30%) para avaliar o desempenho do modelo em dados não vistos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc9133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Divisão dos dados ---\n",
    "y = df[\"MEDV\"]\n",
    "X = df.drop(\"MEDV\", axis=1)\n",
    "\n",
    "# Dividir em treino e teste (70% treino, 30% teste)\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "print(f\"Tamanho do conjunto de treino: {X_treino.shape[0]} amostras\")\n",
    "print(f\"Tamanho do conjunto de teste: {X_teste.shape[0]} amostras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb7fd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Treinamento e avaliação do modelo inicial\n",
    "Vamos treinar modelos iniciais sem seleção de atributos para estabelecer uma linha base de desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a927e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Criação e treinamento dos modelos iniciais ---\n",
    "modelo_regressaolinear = LinearRegression()\n",
    "modelo_arvoredecisao = RandomForestRegressor(random_state=1)\n",
    "\n",
    "# Treinar os modelos\n",
    "modelo_regressaolinear.fit(X_treino, y_treino)\n",
    "modelo_arvoredecisao.fit(X_treino, y_treino)\n",
    "\n",
    "# Fazer previsões\n",
    "previsao_regressaolinear = modelo_regressaolinear.predict(X_teste)\n",
    "previsao_arvoredecisao = modelo_arvoredecisao.predict(X_teste)\n",
    "\n",
    "# Avaliar os modelos\n",
    "rmse_lr = np.sqrt(mean_squared_error(y_teste, previsao_regressaolinear))\n",
    "r2_lr = r2_score(y_teste, previsao_regressaolinear)\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_teste, previsao_arvoredecisao))\n",
    "r2_rf = r2_score(y_teste, previsao_arvoredecisao)\n",
    "\n",
    "print(\"Modelo inicial - Regressão Linear:\")\n",
    "print(f\"RMSE: {rmse_lr:.4f}\")\n",
    "print(f\"R²: {r2_lr:.4f}\")\n",
    "print(\"\\nModelo inicial - Random Forest:\")\n",
    "print(f\"RMSE: {rmse_rf:.4f}\")\n",
    "print(f\"R²: {r2_rf:.4f}\")\n",
    "\n",
    "# Visualizar previsões vs valores reais\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_teste, previsao_regressaolinear, alpha=0.5, label='Regressão Linear')\n",
    "plt.scatter(y_teste, previsao_arvoredecisao, alpha=0.5, label='Random Forest')\n",
    "plt.plot([min(y_teste), max(y_teste)], [min(y_teste), max(y_teste)], 'k--')\n",
    "plt.xlabel('Valores Reais')\n",
    "plt.ylabel('Previsões')\n",
    "plt.legend()\n",
    "plt.title('Previsões vs Valores Reais (Modelos Iniciais)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b092fdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seleção de Atributos\n",
    "Agora vamos aplicar diferentes técnicas de seleção de atributos para identificar as características mais relevantes para o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6f1eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. SelectKBest (baseado em correlação) ---\n",
    "k = 5  # número de atributos a serem selecionados\n",
    "selector_kbest = SelectKBest(score_func=f_regression, k=k)\n",
    "X_treino_kbest = selector_kbest.fit_transform(X_treino, y_treino)\n",
    "X_teste_kbest = selector_kbest.transform(X_teste)\n",
    "\n",
    "# Obter os atributos selecionados\n",
    "atributos_kbest = X.columns[selector_kbest.get_support()]\n",
    "print(\"Atributos selecionados pelo SelectKBest:\")\n",
    "print(list(atributos_kbest))\n",
    "\n",
    "# --- 2. Recursive Feature Elimination (RFE) ---\n",
    "estimator = LinearRegression()\n",
    "selector_rfe = RFE(estimator, n_features_to_select=k)\n",
    "X_treino_rfe = selector_rfe.fit_transform(X_treino, y_treino)\n",
    "X_teste_rfe = selector_rfe.transform(X_teste)\n",
    "\n",
    "# Obter os atributos selecionados pelo RFE\n",
    "atributos_rfe = X.columns[selector_rfe.get_support()]\n",
    "print(\"\\nAtributos selecionados pelo RFE:\")\n",
    "print(list(atributos_rfe))\n",
    "\n",
    "# --- 3. Lasso (regularização L1) ---\n",
    "# Normalizar os dados para Lasso\n",
    "scaler = StandardScaler()\n",
    "X_treino_scaled = scaler.fit_transform(X_treino)\n",
    "X_teste_scaled = scaler.transform(X_teste)\n",
    "\n",
    "# Usar Lasso para seleção de atributos\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_treino_scaled, y_treino)\n",
    "\n",
    "# Identificar coeficientes não-zero (atributos selecionados)\n",
    "coef_lasso = pd.Series(lasso.coef_, index=X.columns)\n",
    "atributos_lasso = coef_lasso[coef_lasso != 0].index.tolist()\n",
    "print(\"\\nAtributos selecionados pelo Lasso:\")\n",
    "print(atributos_lasso)\n",
    "\n",
    "# Visualizar importância dos atributos\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.bar(atributos_kbest, selector_kbest.scores_[selector_kbest.get_support()])\n",
    "plt.title('Importância dos Atributos - SelectKBest')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.bar(atributos_rfe, range(len(atributos_rfe)))\n",
    "plt.title('Atributos Selecionados - RFE')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.bar(X.columns, abs(coef_lasso))\n",
    "plt.title('Coeficientes Lasso')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0162040",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Treinamento e avaliação do modelo com seleção de atributos\n",
    "Agora vamos treinar modelos utilizando apenas os atributos selecionados e comparar seu desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02575c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Treinar modelos com atributos selecionados ---\n",
    "# 1. Modelo com SelectKBest\n",
    "modelo_lr_kbest = LinearRegression().fit(X_treino_kbest, y_treino)\n",
    "modelo_rf_kbest = RandomForestRegressor(random_state=1).fit(X_treino_kbest, y_treino)\n",
    "\n",
    "# 2. Modelo com RFE\n",
    "modelo_lr_rfe = LinearRegression().fit(X_treino_rfe, y_treino)\n",
    "modelo_rf_rfe = RandomForestRegressor(random_state=1).fit(X_treino_rfe, y_treino)\n",
    "\n",
    "# 3. Modelo com Lasso (usando os atributos selecionados)\n",
    "X_treino_lasso = X_treino[atributos_lasso]\n",
    "X_teste_lasso = X_teste[atributos_lasso]\n",
    "modelo_lr_lasso = LinearRegression().fit(X_treino_lasso, y_treino)\n",
    "modelo_rf_lasso = RandomForestRegressor(random_state=1).fit(X_treino_lasso, y_treino)\n",
    "\n",
    "# --- Avaliar todos os modelos ---\n",
    "resultados = pd.DataFrame(columns=['Método', 'Modelo', 'RMSE', 'R²'])\n",
    "\n",
    "# Avaliar modelos iniciais\n",
    "resultados.loc[0] = ['Todos Atributos', 'Linear Regression', rmse_lr, r2_lr]\n",
    "resultados.loc[1] = ['Todos Atributos', 'Random Forest', rmse_rf, r2_rf]\n",
    "\n",
    "# Avaliar modelos com SelectKBest\n",
    "pred_lr_kbest = modelo_lr_kbest.predict(X_teste_kbest)\n",
    "pred_rf_kbest = modelo_rf_kbest.predict(X_teste_kbest)\n",
    "resultados.loc[2] = ['SelectKBest', 'Linear Regression', \n",
    "                    np.sqrt(mean_squared_error(y_teste, pred_lr_kbest)), \n",
    "                    r2_score(y_teste, pred_lr_kbest)]\n",
    "resultados.loc[3] = ['SelectKBest', 'Random Forest', \n",
    "                    np.sqrt(mean_squared_error(y_teste, pred_rf_kbest)), \n",
    "                    r2_score(y_teste, pred_rf_kbest)]\n",
    "\n",
    "# Avaliar modelos com RFE\n",
    "pred_lr_rfe = modelo_lr_rfe.predict(X_teste_rfe)\n",
    "pred_rf_rfe = modelo_rf_rfe.predict(X_teste_rfe)\n",
    "resultados.loc[4] = ['RFE', 'Linear Regression', \n",
    "                    np.sqrt(mean_squared_error(y_teste, pred_lr_rfe)), \n",
    "                    r2_score(y_teste, pred_lr_rfe)]\n",
    "resultados.loc[5] = ['RFE', 'Random Forest', \n",
    "                    np.sqrt(mean_squared_error(y_teste, pred_rf_rfe)), \n",
    "                    r2_score(y_teste, pred_rf_rfe)]\n",
    "\n",
    "# Avaliar modelos com Lasso\n",
    "pred_lr_lasso = modelo_lr_lasso.predict(X_teste_lasso)\n",
    "pred_rf_lasso = modelo_rf_lasso.predict(X_teste_lasso)\n",
    "resultados.loc[6] = ['Lasso', 'Linear Regression', \n",
    "                    np.sqrt(mean_squared_error(y_teste, pred_lr_lasso)), \n",
    "                    r2_score(y_teste, pred_lr_lasso)]\n",
    "resultados.loc[7] = ['Lasso', 'Random Forest', \n",
    "                    np.sqrt(mean_squared_error(y_teste, pred_rf_lasso)), \n",
    "                    r2_score(y_teste, pred_rf_lasso)]\n",
    "\n",
    "# Mostrar resultados\n",
    "print(resultados)\n",
    "\n",
    "# Visualizar comparação dos resultados\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.barplot(x='Método', y='RMSE', hue='Modelo', data=resultados)\n",
    "plt.title('Comparação de RMSE entre Modelos')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.barplot(x='Método', y='R²', hue='Modelo', data=resultados)\n",
    "plt.title('Comparação de R² entre Modelos')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mostrar os coeficientes do melhor modelo de regressão linear\n",
    "# (assumindo que seja o modelo com SelectKBest para este exemplo)\n",
    "print(\"\\nCoeficientes do modelo de regressão linear com SelectKBest:\")\n",
    "print(f'MEDV = {modelo_lr_kbest.intercept_}')\n",
    "for i, coef in enumerate(modelo_lr_kbest.coef_):\n",
    "    print(f'\\t+ {coef:.4f} * {atributos_kbest[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdf3ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Discussão dos resultados\n",
    "Nesta seção, vamos interpretar os resultados obtidos pelos diferentes modelos e técnicas de seleção de atributos.\n",
    "\n",
    "1. **Comparação de técnicas de seleção de atributos**:\n",
    "   - O SelectKBest selecionou atributos baseados na correlação estatística com a variável alvo.\n",
    "   - O RFE utilizou um modelo de regressão para eliminar recursivamente os atributos menos importantes.\n",
    "   - O Lasso utilizou regularização L1 para selecionar atributos, reduzindo alguns coeficientes a zero.\n",
    "\n",
    "2. **Impacto na performance dos modelos**:\n",
    "   - A seleção de atributos geralmente melhorou o desempenho dos modelos ou manteve próximo ao original.\n",
    "   - Modelos de Random Forest continuaram com melhor desempenho que Regressão Linear, mesmo após seleção de atributos.\n",
    "   - A redução no número de atributos simplificou os modelos sem grande perda de desempenho.\n",
    "\n",
    "3. **Interpretabilidade**:\n",
    "   - Os modelos de regressão linear tornaram-se mais interpretáveis após a seleção de atributos.\n",
    "   - É possível entender melhor a contribuição de cada variável no preço das casas.\n",
    "   - Atributos como RM (número de quartos) e LSTAT (status socioeconômico) mostraram-se consistentemente importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421cf758",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conclusão\n",
    "\n",
    "Este trabalho mostrou a aplicação de técnicas de seleção de atributos em um problema de regressão para prever o valor de imóveis em Boston. Principais conclusões:\n",
    "\n",
    "1. A seleção de atributos é uma etapa importante no processo de mineração de dados, pois pode:\n",
    "   - Melhorar o desempenho dos modelos ou manter similar ao original com menos variáveis\n",
    "   - Aumentar a interpretabilidade dos modelos\n",
    "   - Reduzir o custo computacional do treinamento\n",
    "\n",
    "2. Diferentes técnicas de seleção de atributos identificaram conjuntos distintos de características importantes, com algumas sobreposições significativas.\n",
    "\n",
    "3. Os modelos de Random Forest tenderam a superar os modelos de Regressão Linear, mas a diferença diminuiu após a seleção de atributos.\n",
    "\n",
    "4. Em aplicações práticas, a escolha entre um modelo mais complexo e preciso (Random Forest) versus um modelo mais simples e interpretável (Regressão Linear) dependerá do contexto de uso.\n",
    "\n",
    "Trabalhos futuros poderiam explorar outras técnicas de seleção de atributos, algoritmos de regressão mais avançados, e validação cruzada para garantir a robustez dos resultados."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
